# -*- coding: utf-8 -*-
"""URL INSPECTOR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1H6hf0sz2pEhvmaMl8F9SV-EWM9MlKXDZ
"""

pip install requests

import requests
from bs4 import BeautifulSoup

def check_url(url):
    try:
        # Send a request to the URL
        response = requests.get(url)

        # Check if the response is successful (HTTP status code within 200-299)
        if response.status_code >= 200 and response.status_code < 300:
            print(f"The URL {url} is working.")

            # If the response is successful, parse the page and find hyperlinks
            soup = BeautifulSoup(response.content, 'html.parser')
            links = soup.find_all('a', href=True)

            print("Hyperlinks on the page:")
            for link in links:
                print(link['href'])

        else:
            print(f"The URL {url} returned an error: {response.status_code}")

    except requests.exceptions.RequestException as e:
        print(f"An error occurred while checking the URL {url}: {e}")

def check_multiple_urls(urls):
    for url in urls:
        check_url(url)
        print()

# URLs to check
urls_to_check = [
    "https://www.w3schools.com/sql/",
    "https://yournewsreporter.com/advantages-of-buying-authentic-basketball-jerseys/",
    "https://yournewsreporter.com/4-tips-for-selecting-the-best-real-estate-agent/",
]

# Call the function to check the URLs
check_multiple_urls(urls_to_check)

